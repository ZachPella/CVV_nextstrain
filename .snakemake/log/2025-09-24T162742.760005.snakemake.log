Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	align
	1	all
	1	ancestral
	1	export
	1	filter
	1	index_sequences
	1	refine
	1	traits
	1	translate
	1	tree
	10

[Wed Sep 24 16:27:42 2025]
Job 9: 
        Creating an index of sequence composition for filtering.
        

[Wed Sep 24 16:27:43 2025]
Finished job 9.
1 of 10 steps (10%) done

[Wed Sep 24 16:27:43 2025]
Job 8: 
        Filtering to
          - 20 sequence(s) per state year month
          - from 2009 onwards
        

[Wed Sep 24 16:27:44 2025]
Error in rule filter:
    jobid: 8
    output: results/filtered.fasta
    shell:
        
        augur filter             --sequences data/sequences.fasta             --sequence-index results/sequence_index.tsv             --metadata data/metadata.tsv             --output results/filtered.fasta             --group-by state year month             --sequences-per-group 20             --min-date 2009
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job filter since they might be corrupted:
results/filtered.fasta
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/fauverlab/nextstrain/Heartland_build_ZP_September2025/.snakemake/log/2025-09-24T162742.760005.snakemake.log
